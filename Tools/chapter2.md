آموزش الستیک استک - قسمت دوم: مفاهیم جستجو، دقت و یادآوری
این آموزش به بررسی مفاهیم کلیدی جستجو در الستیک‌سرچ، به‌ویژه دقت (Precision) و یادآوری (Recall)، می‌پردازد. هدف این است که با زبانی ساده و قابل فهم، نحوه کار با الستیک‌سرچ و کبانا برای بهبود نتایج جستجو توضیح داده شود. این محتوا بر اساس قسمت دوم دوره فشرده آموزش الستیک استک تهیه شده و شامل مثال‌های عملی و توضیحات گام‌به‌گام است.

مقدمه
در این بخش، ما بر روی الستیک‌سرچ، قلب الستیک استک، تمرکز می‌کنیم. الستیک‌سرچ یک موتور جستجو و تحلیل داده است که در بسیاری از برنامه‌های روزمره مانند Yelp یا Instacart برای جستجوی سریع و مرتبط استفاده می‌شود. در این آموزش، شما با مفاهیم زیر آشنا خواهید شد:

دقت (Precision) و یادآوری (Recall) در جستجو
نحوه محاسبه امتیاز (Score) اسناد
فرکانس ترم (Term Frequency) و فرکانس معکوس سند (Inverse Document Frequency)
استفاده از کبانا برای ارسال کوئری‌ها و بهبود نتایج جستجو
کار با داده‌ها و تنظیمات در الستیک کلود


مرور قسمت اول
در قسمت اول این دوره:

به موارد استفاده هیجان‌انگیز الستیک استک پرداختیم.
معماری الستیک‌سرچ را بررسی کردیم.
عملیات CRUD (ایجاد، خواندن، به‌روزرسانی، حذف) را با استفاده از الستیک‌سرچ و کبانا انجام دادیم.

اگر قسمت اول را از دست داده‌اید، می‌توانید به مخزن گیت‌هاب که لینک آن در چت ارائه شده مراجعه کنید. این مخزن شامل ویدیو و مطالب مربوط به قسمت اول است.

الستیک استک چیست؟
الستیک استک شامل چهار محصول اصلی است:

Beats: برای جمع‌آوری داده‌ها
Logstash: برای پردازش و انتقال داده‌ها
Elasticsearch: موتور جستجو و تحلیل
Kibana: رابط کاربری برای تجسم و کاوش داده‌ها

با این استک، می‌توانید داده‌ها را از هر منبعی با هر فرمتی دریافت کرده، جستجو، تحلیل و به‌صورت بلادرنگ تجسم کنید.

مفاهیم کلیدی جستجو
جستجو چیست؟
جستجو بخشی از تجربه کاربری است. چه در حال جستجوی یک رستوران باشید یا یک مستند، انتظار دارید نتایج سریع و مرتبط باشند. الستیک‌سرچ این امکان را فراهم می‌کند که جستجوهای سریع و در مقیاس بزرگ انجام شود. در این آموزش، بر روی مربوط بودن (Relevance) نتایج تمرکز می‌کنیم.
دقت (Precision) و یادآوری (Recall)
دقت و یادآوری دو معیار اصلی برای ارزیابی کیفیت نتایج جستجو هستند:

دقت (Precision):

به درصدی از نتایج بازگردانده‌شده اشاره دارد که واقعاً مرتبط هستند.
فرمول:[Precision = \frac{\text{True Positives}}{\text{True Positives} + \text{False Positives}}]
True Positives: اسنادی که مرتبط هستند و به درستی بازگردانده شده‌اند.
False Positives: اسنادی که غیرمرتبط هستند اما به اشتباه بازگردانده شده‌اند.
دقت بالا به این معناست که نتایج کمتری بازگردانده می‌شود، اما این نتایج بسیار مرتبط هستند.


یادآوری (Recall):

به درصدی از اسناد مرتبط اشاره دارد که توسط موتور جستجو بازگردانده شده‌اند.
فرمول:[Recall = \frac{\text{True Positives}}{\text{True Positives} + \text{False Negatives}}]
False Negatives: اسناد مرتبطی که به اشتباه بازگردانده نشده‌اند.
یادآوری بالا به این معناست که تعداد بیشتری از اسناد مرتبط بازگردانده می‌شود، حتی اگر شامل برخی نتایج غیرمرتبط باشد.



رابطه دقت و یادآوری
دقت و یادآوری رابطه معکوس دارند:

افزایش دقت ممکن است باعث کاهش یادآوری شود (نتایج کمتر اما دقیق‌تر).
افزایش یادآوری ممکن است باعث کاهش دقت شود (نتایج بیشتر اما با احتمال وجود نتایج غیرمرتبط).

رتبه‌بندی (Ranking) و امتیازدهی (Scoring)

الستیک‌سرچ نتایج را بر اساس امتیاز (Score) رتبه‌بندی می‌کند.
اسناد با امتیاز بالاتر در بالای نتایج قرار می‌گیرند.
امتیاز هر سند بر اساس فاکتورهایی مانند فرکانس ترم (Term Frequency) و فرکانس معکوس سند (Inverse Document Frequency) محاسبه می‌شود.

فرکانس ترم (Term Frequency)

تعداد دفعاتی که یک ترم (کلمه جستجو) در یک سند ظاهر می‌شود.
مثال: اگر در کوئری «how to form good habits» کلمه «habits» در یک سند ۴ بار و در سند دیگر ۱ بار ظاهر شود، سند اول امتیاز بالاتری می‌گیرد.

فرکانس معکوس سند (Inverse Document Frequency)

ترم‌هایی که در اسناد زیادی ظاهر می‌شوند (مانند «how» یا «to») ارزش کمتری برای تعیین ارتباط دارند.
الستیک‌سرچ امتیاز اسنادی که شامل ترم‌های رایج هستند را کاهش و اسنادی که شامل ترم‌های خاص (مانند «habits») هستند را افزایش می‌دهد.


راه‌اندازی الستیک کلود
برای این آموزش، به جای نصب محلی الستیک‌سرچ و کبانا، از الستیک کلود استفاده می‌کنیم، زیرا اجرای همزمان دمو و اشتراک‌گذاری صفحه نمایش در زوم می‌تواند کند باشد.
مراحل راه‌اندازی

به لینک مخزن گیت‌هاب (ارائه‌شده در چت) مراجعه کنید.
در بخش منابع، لینک آزمایش رایگان الستیک کلود را پیدا کنید.
روی لینک کلیک کرده و یک حساب با ایمیل خود ایجاد کنید (بدون نیاز به کارت اعتباری، با ۳۰ روز دسترسی رایگان).
ایمیل تأیید را بررسی و رمز عبور تنظیم کنید.
در صفحه تنظیمات:
الستیک استک را انتخاب کنید.
پروفایل سخت‌افزاری را روی I/O Optimized تنظیم کنید.
یک ارائه‌دهنده ابری (مثل AWS یا Google Cloud) و منطقه نزدیک به خود انتخاب کنید.
آخرین نسخه الستیک استک (مثلاً 7.10.1) را انتخاب کنید.
نامی برای دیپلوی‌منت خود انتخاب کنید (مثلاً «Beginner’s Crash Course»).


پس از ایجاد دیپلوی‌منت، اطلاعات ورود (Credentials) را ذخیره کنید.
روی Open Kibana کلیک کنید تا به کبانا دسترسی پیدا کنید.


وارد کردن داده‌ها به الستیک‌سرچ
برای کاوش در مفاهیم جستجو، از مجموعه داده‌ای از سرخط‌های خبری هاف‌پست (۲۰۱۲-۲۰۱۸) استفاده می‌کنیم که از Kaggle گرفته شده است. این داده‌ها در مخزن گیت‌هاب در دسترس است.
مراحل وارد کردن داده‌ها

در کبانا، به صفحه اصلی بروید و گزینه Upload a File را انتخاب کنید.
فایل داده (NDJSON) را دانلود و از حالت فشرده خارج کنید.
فایل را در کبانا آپلود کنید.
کبانا تحلیل اولیه‌ای از ۱۰۰۰ خط اول داده ارائه می‌دهد:
داده‌ها شامل سرخط‌های خبری در دسته‌بندی‌هایی مانند «Crime» یا «Entertainment» هستند.
فیلدهای هر سند شامل نویسندگان، دسته‌بندی‌ها، سرخط‌ها و غیره است.


یک نام برای ایندکس انتخاب کنید (مثلاً «news_headlines»، همه حروف کوچک).
روی Import کلیک کنید تا داده‌ها به الستیک‌سرچ وارد شوند.


کاوش داده‌ها با کبانا
برای کاوش و بهبود نتایج جستجو، از کنسول کبانا استفاده می‌کنیم:

در کبانا، روی آیکون منو (گوشه بالا سمت چپ) کلیک کنید.
به بخش Management بروید و Dev Tools را انتخاب کنید.
کنسول کبانا باز می‌شود، جایی که می‌توانید کوئری‌ها را ارسال کنید.

هدف‌ها

جستجوی اطلاعات در داده‌ها.
تنظیم دقت یا یادآوری نتایج جستجو.


کوئری‌های جستجو
۱. بازیابی همه اسناد از یک ایندکس
برای بررسی ساختار اسناد و تعداد آن‌ها:
GET news_headlines/_search


این کوئری تمام اسناد موجود در ایندکس «news_headlines» را برمی‌گرداند.
به طور پیش‌فرض، ۱۰ نتیجه نمایش داده می‌شود.
در پاسخ، در خط ۱۰، فیلد hits.total.value تعداد کل اسناد را نشان می‌دهد (محدود به ۱۰,۰۰۰ برای سرعت بیشتر).
اگر فیلد hits.total.relation برابر با gte باشد، تعداد واقعی ممکن است بیشتر از ۱۰,۰۰۰ باشد.

تعداد دقیق اسناد
برای دریافت تعداد دقیق:
GET news_headlines/_search?track_total_hits=true


این کوئری تعداد دقیق اسناد (مثلاً ۲۰۰,۸۵۳) را برمی‌گرداند.
فیلد hits.total.relation برابر با eq خواهد بود.

۲. جستجو در بازه زمانی خاص
برای محدود کردن جستجو به یک بازه زمانی:
GET news_headlines/_search
{
  "query": {
    "range": {
      "date": {
        "gte": "2015-01-01",
        "lte": "2016-12-31"
      }
    }
  }
}


این کوئری اسنادی را برمی‌گرداند که بین سال‌های ۲۰۱۵ و ۲۰۱۶ منتشر شده‌اند.
نتیجه: حدود ۸,۰۰۰ سند.

۳. تجمیع (Aggregations)
برای تحلیل دسته‌بندی‌های خبری موجود:
GET news_headlines/_search
{
  "aggs": {
    "by_category": {
      "terms": {
        "field": "category",
        "size": 100
      }
    }
  }
}


این درخواست تا ۱۰۰ دسته‌بندی را با تعداد مقالات هر دسته نمایش می‌دهد (مثل Politics، Wellness، Entertainment).

۴. ترکیب کوئری و تجمیع
برای تحلیل موضوعات محبوب در دسته‌بندی «Entertainment»:
GET news_headlines/_search
{
  "query": {
    "match": {
      "category": "ENTERTAINMENT"
    }
  },
  "aggs": {
    "popular_in_entertainment": {
      "significant_text": {
        "field": "headline"
      }
    }
  }
}


این کوئری ابتدا اسناد دسته‌بندی «Entertainment» را فیلتر می‌کند، سپس موضوعات مهم (مثل «trailer»، «movies»، «Kardashian») را استخراج می‌کند.

۵. بهبود دقت و یادآوری
کوئری با منطق OR (یادآوری بالا)
برای جستجوی سرخط‌هایی که شامل «Khloe» یا «Kardashian» یا «Kendall» یا «Jenner» باشند:
GET news_headlines/_search
{
  "query": {
    "match": {
      "headline": "Khloe Kardashian Kendall Jenner"
    }
  }
}


نتیجه: ۹۲۶ سند، شامل اسنادی که تنها یکی از ترم‌ها را دارند (یادآوری بالا، دقت پایین).

کوئری با منطق AND (دقت بالا)
برای افزایش دقت، از عملگر AND استفاده می‌کنیم:
GET news_headlines/_search
{
  "query": {
    "match": {
      "headline": {
        "query": "Khloe Kardashian Kendall Jenner",
        "operator": "AND"
      }
    }
  }
}


نتیجه: تنها ۱ سند که شامل هر چهار ترم است (دقت بالا، یادآوری پایین).

تنظیم تعادل با minimum_should_match
برای تعادل بین دقت و یادآوری:
GET news_headlines/_search
{
  "query": {
    "match": {
      "headline": {
        "query": "Khloe Kardashian Kendall Jenner",
        "minimum_should_match": 3
      }
    }
  }
}


این کوئری اسنادی را برمی‌گرداند که حداقل ۳ ترم از ۴ ترم را دارند.
نتیجه: ۶ سند، با تعادل بهتر بین دقت و یادآوری.


پاسخ به سؤالات
۱. ترکیب رتبه‌بندی و مرتب‌سازی

بله، می‌توان چندین کوئری را با استفاده از Bool Query ترکیب کرد.
Bool Query شامل ۴ بند است: must، must_not، should، filter.
مثال:

GET news_headlines/_search
{
  "query": {
    "bool": {
      "must": [
        { "match": { "category": "ENTERTAINMENT" } }
      ],
      "should": [
        { "match": { "headline": "Kardashian" } }
      ],
      "minimum_should_match": 1
    }
  }
}


این کوئری اسناد دسته‌بندی «Entertainment» را فیلتر می‌کند و امتیاز اسنادی که شامل «Kardashian» هستند را افزایش می‌دهد.

۲. حذف مجموعه داده
برای حذف یک ایندکس (مثل «news_headlines»):
DELETE news_headlines


پاسخ acknowledged: true نشان‌دهنده حذف موفق است.
برای اطمینان، کوئری زیر را اجرا کنید:

GET news_headlines/_search


اگر خطای «index_not_found» دریافت کردید، ایندکس حذف شده است.

۳. تنظیم Mapping هنگام وارد کردن داده

هنگام آپلود داده در کبانا، می‌توانید تنظیمات Mapping را تغییر دهید:
روی Override Settings کلیک کنید.
نام فیلدها و انواع داده را ویرایش کنید.
برای تنظیمات پیشرفته‌تر، روی Advanced Options کلیک کنید و Mapping را تنظیم کنید.




جمع‌بندی
در این آموزش:

مفاهیم دقت و یادآوری را بررسی کردیم.
نحوه محاسبه امتیاز اسناد با استفاده از فرکانس ترم و فرکانس معکوس سند را آموختیم.
با استفاده از کبانا، کوئری‌های جستجو و تجمیع را اجرا کردیم.
یاد گرفتیم چگونه دقت و یادآوری را با استفاده از عملگرهای AND و minimum_should_match تنظیم کنیم.

برای ادامه یادگیری:

به کارگاه بعدی در تاریخ ۲۴ فوریه (ساعت ۱۲ ظهر به وقت مرکزی) بپیوندید که درباره کوئری‌های متنی کامل است.
سؤالات خود را در فروم بحث الستیک مطرح کنید.
وبلاگ‌های الستیک‌سرچ را برای یادگیری بیشتر مطالعه کنید.


تصاویر پیشنهادی
برای درک بهتر مفاهیم دقت و یادآوری، تصاویر زیر می‌توانند به آموزش اضافه شوند:

دیاگرام دقت و یادآوری:
یک مستطیل زرد (ایندکس) با نقاط خاکستری (اسناد).
دایره سفید داخل آن نشان‌دهنده اسناد بازگردانده‌شده (True Positives و False Positives).
نقاط زرد خارج از دایره نشان‌دهنده False Negatives و True Negatives.


دیاگرام رتبه‌بندی:
نمایش اسناد با امتیازات مختلف که از بالا (امتیاز بالا) به پایین (امتیاز پایین) مرتب شده‌اند.



توجه: اگر نیاز به تولید این تصاویر دارید، لطفاً تأیید کنید تا با ابزارهای مناسب آن‌ها را ایجاد کنم.


برای توضیح تفاوت **TF-IDF** در جستجوی متن در موتورهای جستجو مثل الستیک‌سرچ، بیایید ابتدا مفهوم آن را ساده کنیم و سپس با یک مثال کاربردی در الستیک‌سرچ نشان دهیم.

### TF-IDF چیست؟
**TF-IDF** (Term Frequency - Inverse Document Frequency) یک الگوریتم وزن‌دهی است که در جستجوی متنی برای ارزیابی اهمیت یک کلمه در یک سند (داکیومنت) نسبت به کل مجموعه اسناد (ایندکس) استفاده می‌شود. این الگوریتم دو بخش اصلی دارد:

1. **TF (Term Frequency)**: تعداد دفعاتی که یک کلمه در یک سند خاص ظاهر می‌شود، تقسیم بر تعداد کل کلمات در آن سند. این نشان‌دهنده اهمیت کلمه در آن سند است.
2. **IDF (Inverse Document Frequency)**: معیاری که نشان می‌دهد یک کلمه چقدر در کل مجموعه اسناد نادر یا رایج است. اگر کلمه‌ای در اسناد زیادی باشد (مثل "و" یا "از")، وزن کمتری می‌گیرد.

**فرمول کلی TF-IDF**:
```
TF-IDF = TF * IDF
```
- `TF = (تعداد تکرار کلمه در سند) / (تعداد کل کلمات در سند)`
- `IDF = log(تعداد کل اسناد / تعداد اسنادی که کلمه در آن‌ها ظاهر شده)`

### چرا TF-IDF مهم است؟
TF-IDF به موتور جستجو کمک می‌کند تا اسنادی را که واقعاً مرتبط با عبارت جستجو هستند، اولویت‌بندی کند. کلمات نادر که معنای خاص‌تری دارند (مثل "الستیک‌سرچ") وزن بیشتری می‌گیرند نسبت به کلمات رایج (مثل "این").

### مثال ساده در الستیک‌سرچ
فرض کنید یک ایندکس به نام `books` داریم که شامل سه سند است:

1. **سند 1**: "آموزش الستیک‌سرچ برای جستجوی سریع"
2. **سند 2**: "جستجوی متنی با الستیک‌سرچ"
3. **سند 3**: "آموزش سریع پایتون"

حالا فرض کنید کاربر عبارت **"الستیک‌سرچ"** را جستجو می‌کند.

#### مرحله 1: محاسبه TF
- **کلمه "الستیک‌سرچ"**:
  - در سند 1: 1 بار ظاهر شده، کل کلمات سند 5 تا → `TF = 1/5 = 0.2`
  - در سند 2: 1 بار ظاهر شده، کل کلمات سند 4 تا → `TF = 1/4 = 0.25`
  - در سند 3: 0 بار ظاهر شده → `TF = 0`

- **کلمه "جستجوی"** (اگر کاربر مثلاً "جستجوی الستیک‌سرچ" را سرچ کند):
  - در سند 1: 1 بار، `TF = 1/5 = 0.2`
  - در سند 2: 1 بار، `TF = 1/4 = 0.25`
  - در سند 3: 0 بار، `TF = 0`

#### مرحله 2: محاسبه IDF
- **کلمه "الستیک‌سرچ"**:
  - تعداد کل اسناد: 3
  - تعداد اسنادی که "الستیک‌سرچ" در آن‌ها ظاهر شده: 2 (سند 1 و 2)
  - `IDF = log(3/2) ≈ 0.176`
- **کلمه "جستجوی"**:
  - تعداد اسنادی که "جستجوی" در آن‌ها ظاهر شده: 2 (سند 1 و 2)
  - `IDF = log(3/2) ≈ 0.176`

#### مرحله 3: محاسبه TF-IDF
- برای **"الستیک‌سرچ"**:
  - سند 1: `TF-IDF = 0.2 * 0.176 = 0.0352`
  - سند 2: `TF-IDF = 0.25 * 0.176 = 0.044`
  - سند 3: `TF-IDF = 0 * 0.176 = 0`
- برای **"جستجوی"** (در صورت جستجوی ترکیبی):
  - سند 1: `TF-IDF = 0.2 * 0.176 = 0.0352`
  - سند 2: `TF-IDF = 0.25 * 0.176 = 0.044`
  - سند 3: `TF-IDF = 0`

#### مرحله 4: رتبه‌بندی در الستیک‌سرچ
الستیک‌سرچ امتیاز هر سند را با ترکیب TF-IDF کلمات جستجو محاسبه می‌کند. در اینجا:
- سند 2 امتیاز بالاتری دارد (چون TF بالاتری برای "الستیک‌سرچ" دارد).
- سند 1 در رتبه بعدی قرار می‌گیرد.
- سند 3 چون کلمه "الستیک‌سرچ" را ندارد، در نتایج ظاهر نمی‌شود یا امتیاز صفر می‌گیرد.

### اجرای کوئری در Dev Tools کیبانا
برای جستجوی عبارت "الستیک‌سرچ" در ایندکس `books`، می‌توانید این کوئری را در Dev Tools اجرا کنید:

```json
GET /books/_search
{
  "query": {
    "match": {
      "content": "الستیک‌سرچ"
    }
  }
}
```

#### خروجی نمونه:
```json
{
  "hits": {
    "total": { "value": 2 },
    "hits": [
      {
        "_id": "2",
        "_score": 0.287,  // امتیاز بالاتر به دلیل TF بالاتر
        "_source": { "content": "جستجوی متنی با الستیک‌سرچ" }
      },
      {
        "_id": "1",
        "_score": 0.231,
        "_source": { "content": "آموزش الستیک‌سرچ برای جستجوی سریع" }
      }
    ]
  }
}
```

### تفاوت کلیدی TF-IDF
- **TF**: باعث می‌شود کلماتی که در یک سند بیشتر تکرار شده‌اند، وزن بیشتری داشته باشند.
- **IDF**: کلمات نادر (مثل "الستیک‌سرچ") را مهم‌تر از کلمات رایج (مثل "آموزش") می‌کند.
- در مثال بالا، "الستیک‌سرچ" چون در کل اسناد نادرتر است، وزن بیشتری در رتبه‌بندی دارد و سند 2 به دلیل تراکم بالاتر این کلمه، رتبه بهتری می‌گیرد.

### نکته در الستیک‌سرچ
الستیک‌سرچ از مدل **BM25** (نسخه بهبودیافته TF-IDF) به‌صورت پیش‌فرض استفاده می‌کند. BM25 محدودیت‌های TF-IDF (مثل حساسیت به طول سند) را بهبود داده، اما مفهوم کلی مشابه است.

اگر سوال بیشتری دارید یا نیاز به مثال دیگری بود، بگویید!
