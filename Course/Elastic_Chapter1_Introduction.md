
# آموزش دنیای الستیک - قسمت اول معرفی الستیک

سلام! به قسمت اول دوره‌ی استیک Elastic خوش آمدید. اینجا قرار است از صفرِ صفرِ صفر شروع کنیم.
ابتدا روی مفاهیم و الفبای التسیک تمرکز می کنیم ، بعد از یادگیری مفاهیم عمیق الستیک به سمت کاربرد و اهداف آن پیش می رویم.
هدف این قسمت اینه که با زبانی ساده و مثال‌های ملموس درعین حال با تکیه بر تحلیل عمیق، پایه‌ی فکری محکمی برای ورود به دنیای Elastic بسازید.
بیایید شروع کنیم!

---
### 🗒️ مقدمه
الآن که باهم داریم این دوره رو شروع میکنیم با توجه به فراگیری تکنولوژی ها و سرویس های آنلاین و آفلاین و افزایش حجم کاربران درگیر با سیستم های دیجیتالی و مخصوصا بر پایه ی وب ، مسئله پایداری سیستم و حفظ آن از مهمترین مسائل دنیای تکنولوژی میباشدو سود و ضرر های هنگفتی در اثر مدیریت یا سوءمدیریت این مسئله ممکن است رخ بدهد.

امروزه هرجا سخنی از یک سرویس یا اپلیکیشنی میشود بعد از آن صحبت از مانیتورینگ ، تحلیل داده های وضعیتی و هشداری و عملگرایی بلادرنگ برای حفظ سیستم مطرح میشود و این یک واقعیت گریزناپذیر است. از طرفی هم با افزایش پیچیدگی سیستم‌ها، نیاز به پردازش، ذخیره‌سازی، جستجو و تحلیل این داده‌هایی که گزارشی از وضعیت سیستم هستند (مثل لاگ ها) نیز افزایش پیدا می‌کند.

وقتی اپلیکیشن‌ها و سیستم‌ها به شدت توزیع‌ شده ، پیچیده و چند لایه شدند[مخصوصا با ظهور و بروز و همه گیر شدن معماری میکروسرویس که هر سرویس کوچک یا بزرگ ، پروسه و داده های خاص خود را دارد شاید افزونگی و وابستگی کل به جز رو تا حدی حل کرد] آنوقت صحبت این شد که حالا چجوری داده های تک تک این لایه ها یا بخش ها را از هم جدا کنیم، طبقه بندی کنیم ، ذخیره کنیم ، تحلیل کنیم ، از بین آنها به صورت بهینه در جست و جوی چیز خاصی باشیم و در نهایت تصمیم گیری درست در مورد هر یک به صورت جداگانه بکنیم !!؟؟

> چون هر کدام از این اجزا لاگ‌هایی تولید می‌کنند که می‌توانند شامل اطلاعات بسیار مهمی برای تشخیص خطا، تحلیل رفتار کاربر، پایش سلامت سیستم و حتی امنیت باشند. اما این لاگ‌ها حجم زیادی دارند و جستجوی سریع و تحلیلی در آن‌ها نیاز به ابزاری فراتر از دیتابیس‌های سنتی داشت.

 ### 🏷️ در اینجا بود که الستیک سرچ (Elasticsearch) به دنیا آمد.
ابتدا به عنوان یک موتور جستجوی متن‌باز برای جستجوی متن کامل در مقیاس بالا توسعه داده شد و بعدها در کنار ابزارهایی مثل **Logstash** و **Kibana** تبدیل به یک پلتفرم کامل به نام **Elastic Stack** یا به‌اختصار **ELK Stack** شد.

---



### 🧑‍🍳 داستان ظهور Elastic

استک Elastic (که گاهی بهش ELK Stack هم می‌گن، یعنی مخفف Elasticsearch، Logstash و Kibana) داستانش از سال ۲۰۱۰ شروع می‌شه.

#### 😵‍💫 مشکل Shay 

در سال ۲۰۱۰، Shay Banon در حال ساخت یک اپلیکیشن آشپزی برای همسرش بود که با یک مشکل مشخص روبه‌رو شد:
- **ساختن یک سیستم جستجوی ساده و کارآمد برای حجم زیادی از داده‌ها سخت بود.**
همسر Shay یه مجموعه‌ی بزرگ از دستور پخت‌ها داشت. Shay می‌خواست برای همسرش که در حال تحصیل برای سرآشپز شدن بود، یک ابزار جستجو درست کنه تا بتونه توی مجموعه‌ی بزرگ دستور پخت‌ها (recipes) به راحتی جستجو کنه.
 > مثلاً اگه همسرش می‌خواست دستور پخت‌هایی با "ماهی" پیدا کنه که کمتر از ۴۰۰ کالری داشته باشن، این نرم‌افزار باید سریع جواب می‌داد. 
 > یا مثلاً بگه کدوم دستورها "مرغ" دارن یا کدوم‌ها سریع آماده می‌شن.

در اون زمان، Shay از **Apache Lucene** استفاده می‌کرد، که یه کتابخونه‌ی متن‌باز و قدرتمند برای جستجو بود. 
این نیاز شخصی، جرقه‌ی اولیه‌ی ساخت Elasticsearch رو زد.


⚠️ اما Lucene یه مشکل بزرگ داشت:
-  **سطح پایین (low-level) بود**
-  **استفاده ازش پیچیده و زمان‌بر بود.**

 آقای Shay دنبال سیستمی بود که هم قدرتمند باشه، هم مقیاس‌پذیر، و هم استفاده‌ش برای توسعه‌دهنده‌ها راحت باشه.
 درد اصلیش این بود که نمی‌خواست وقت زیادی صرف مدیریت جزئیات فنی پیچیده کنه. یا به قول معروف نمیخواست خودشو درگیر سطوح پایین پردازشی کند و یک لایه ی سطح بالاتر نیاز داشت.


#### حالا مگه Apache Lucene چه سختی‌ای داشت؟

سرویس Lucene یه کتابخونه‌ی قوی برای جستجو بود، اما چون سطح پایین بود، توسعه‌دهنده رو مجبور می‌کرد خیلی از کارها رو دستی انجام بده.

---
### اگر در مورد شاخص گذاری (Indexing) اطلاعاتی ندارید ، فایل مربوطه رو بخونید . [Indexing](https://github.com/amirbnprogramming/Elastic/blob/main/Course/Elastic_Chapter0_CrashConcepts_Indexing.md)
---

#### برگردیم به بحث سختی‌های سیستم Apache Lucene اینا بودن 😵‍💫

- **مدیریت ایندکسینگ**: باید خودتون داده‌ها رو تبدیل به ایندکس می‌کردید، مثلاً متن رو به فهرست معکوس (inverted index) تبدیل کنید.
- **توزیع‌شدگی**: اگه داده‌ها زیاد باشن و روی یه سرور جا نشن، باید خودتون سیستم رو بین چند سرور پخش کنید.
  > که یعنی کد نویسی شبکه و هماهنگی سرورها.
- **مقیاس‌پذیری و اطمینان**: برای اینکه سیستم با داده‌های بزرگ کار کنه و خراب نشه، باید خودتون replication (کپی داده‌ها) و failover (جابجایی در صورت خرابی) رو پیاده‌سازی کنید.
- **عدم وجود API ساده**: برای جستجو، باید خودتون یه رابط کاربری یا API درست می‌کردید.

#### مثال عملی از سختی Lucene:
فرض کنید یه وب‌سایت خبری با ۵ میلیون مقاله دارید و می‌خواهید کاربران بتونن توی مقالات جستجو کنن.

با Lucene باید مراحل زیر رو طی کنید:

1. باید کدی بنویسید که هر مقاله رو بخونه و ایندکس کنه (مثلاً کلمات کلیدی رو استخراج کنه).
2. اگه داده‌ها روی یه سرور جا نشن، باید خودتون سرورها رو هماهنگ کنید و ایندکس‌ها رو پخش کنید.
3. اگه یه سرور خراب بشه، باید خودتون مطمئن بشید که داده‌ها از دست نمیرن.
4. برای جستجوی کاربرها (مثلاً "اخبار ورزشی")، باید یه API جدا بسازید.

این کارها برای یه پروژه‌ی ساده مثل دستور پخت‌ها هم خیلی زیاد بود و Shay رو کلافه کرده بود.


---

#### 🦉 راهکار Shay چی بود؟

آقای Shay تصمیم گرفت یه لایه‌ی جدید روی Lucene بسازد که این مشکلات رو حل کنه.
> راهکارش **Elasticsearch** بود، یه موتور جستجو و تحلیل توزیع‌شده که استفاده ازش **ساده** باشه و از طرفی هم **قدرت** Lucene رو داشته باشه.

#### از نظر تئوریک:
- **پنهان کردن پیچیدگی‌ها**: Elasticsearch از Lucene به عنوان هسته‌ی جستجوش استفاده کرد، اما پیچیدگی‌های مدیریت ایندکس، توزیع‌شدگی و مقیاس‌پذیری رو خودش بر عهده گرفت.
- **معماری توزیع‌شده**: داده‌ها رو به صورت خودکار توی شارد‌ها (shards) پخش کرد و با replica‌ها (کپی‌ها) از خرابی جلوگیری کرد.
- **رابط کاربری ساده**: یه API RESTful با فرمت JSON اضافه کرد که کار باهاش برای توسعه‌دهنده‌ها راحت باشه.

#### از نظر عملی:
- **ارسال داده‌ها**: شما فقط داده‌ها رو به Elasticsearch می‌فرستید، اون خودش ایندکسینگ و پخش کردن داده‌ها رو مدیریت می‌کنه.
- **جستجوی سریع**: با یه درخواست ساده، می‌تونید توی داده‌ها جستجو کنید.
- **مقیاس‌پذیری خودکار**: اگه داده‌ها زیاد بشن، فقط سرور اضافه می‌کنید و Elasticsearch بقیه کار رو انجام می‌ده.

#### مثال عملی با Elasticsearch:
برگردیم به وب‌سایت خبری با ۵ میلیون مقاله. با Elasticsearch:
1. مقالات رو به صورت JSON می‌فرستید:
```json
{
     "title": "Today's Sport News",
     "content": "Barcelona team did ...",
     "date": "2023-10-01"
}
```

2. اکوسیستم Elasticsearch خودش داده‌ها رو ایندکس می‌کنه و توی شارد‌ها پخش می‌کنه.
3. برای جستجو، یه درخواست ساده می‌فرستید:
   ```
   GET /news/_search?q=sport
   ```
   و فوراً نتایج رو می‌گیرید، بدون اینکه نگران سرورها یا خرابی باشید.


### خلاصه تاریخجه
مشکل Shay این بود که ساختن یه سیستم جستجوی مقیاس‌پذیر با Apache Lucene خیلی پیچیده و سخت بود، چون Lucene یه کتابخونه‌ی سطح پایین بود و مدیریتش دستی بود. این مشکل از پروژه‌ی نرم‌افزار آشپزی برای دستور پخت‌های همسرش شروع شد. راهکارش Elasticsearch بود که از نظر تئوریک، پیچیدگی‌های Lucene رو پنهان کرد و از نظر عملی، یه سیستم ساده، توزیع‌شده و قدرتمند ارائه داد که توسعه‌دهنده‌ها بتونن راحت ازش استفاده کنن.

او نیاز به یک موتور جستجوی قوی داشت اما ابزارهای موجود مثل Solr پیچیده بودند.
آقای Shay این لایه رو اضافه کرد و Elasticsearch متولد شد. بعداً ابزارهای Logstash، Kibana و Beats بهش اضافه شدن تا استک کامل بشه.

- 2010: انتشار اولیه Elasticsearch
- 2013: اضافه شدن Logstash به استک
- 2015: معرفی Kibana و Beats
- امروز: یک پلتفرم کامل برای Observability, Security و Enterprise Search
---

