
# آموزش دنیای الستیک - قسمت اول معرفی الستیک

سلام! به قسمت اول دوره‌ی استیک Elastic خوش آمدید. اینجا قرار است از صفرِ صفرِ صفر شروع کنیم.
ابتدا روی مفاهیم و الفبای التسیک تمرکز می کنیم ، بعد از یادگیری مفاهیم عمیق الستیک به سمت کاربرد و اهداف آن پیش می رویم.
هدف این قسمت اینه که با زبانی ساده و مثال‌های ملموس درعین حال با تکیه بر تحلیل عمیق، پایه‌ی فکری محکمی برای ورود به دنیای Elastic بسازید.
بیایید شروع کنیم!

---
### 🗒️ مقدمه
الآن که باهم داریم این دوره رو شروع میکنیم با توجه به فراگیری تکنولوژی ها و سرویس های آنلاین و آفلاین و افزایش حجم کاربران درگیر با سیستم های دیجیتالی و مخصوصا بر پایه ی وب ، مسئله پایداری سیستم و حفظ آن از مهمترین مسائل دنیای تکنولوژی میباشدو سود و ضرر های هنگفتی در اثر مدیریت یا سوءمدیریت این مسئله ممکن است رخ بدهد.

امروزه هرجا سخنی از یک سرویس یا اپلیکیشنی میشود بعد از آن صحبت از مانیتورینگ ، تحلیل داده های وضعیتی و هشداری و عملگرایی بلادرنگ برای حفظ سیستم مطرح میشود و این یک واقعیت گریزناپذیر است. از طرفی هم با افزایش پیچیدگی سیستم‌ها، نیاز به پردازش، ذخیره‌سازی، جستجو و تحلیل این داده‌هایی که گزارشی از وضعیت سیستم هستند (مثل لاگ ها) نیز افزایش پیدا می‌کند.

وقتی اپلیکیشن‌ها و سیستم‌ها به شدت توزیع‌ شده ، پیچیده و چند لایه شدند[مخصوصا با ظهور و بروز و همه گیر شدن معماری میکروسرویس که هر سرویس کوچک یا بزرگ ، پروسه و داده های خاص خود را دارد شاید افزونگی و وابستگی کل به جز رو تا حدی حل کرد] آنوقت صحبت این شد که حالا چجوری داده های تک تک این لایه ها یا بخش ها را از هم جدا کنیم، طبقه بندی کنیم ، ذخیره کنیم ، تحلیل کنیم ، از بین آنها به صورت بهینه در جست و جوی چیز خاصی باشیم و در نهایت تصمیم گیری درست در مورد هر یک به صورت جداگانه بکنیم !!؟؟

> چون هر کدام از این اجزا لاگ‌هایی تولید می‌کنند که می‌توانند شامل اطلاعات بسیار مهمی برای تشخیص خطا، تحلیل رفتار کاربر، پایش سلامت سیستم و حتی امنیت باشند. اما این لاگ‌ها حجم زیادی دارند و جستجوی سریع و تحلیلی در آن‌ها نیاز به ابزاری فراتر از دیتابیس‌های سنتی داشت.

 ### 🏷️ در اینجا بود که الستیک سرچ (Elasticsearch) به دنیا آمد.
ابتدا به عنوان یک موتور جستجوی متن‌باز برای جستجوی متن کامل در مقیاس بالا توسعه داده شد و بعدها در کنار ابزارهایی مثل **Logstash** و **Kibana** تبدیل به یک پلتفرم کامل به نام **Elastic Stack** یا به‌اختصار **ELK Stack** شد.

---



### 🧑‍🍳 داستان ظهور Elastic

استک Elastic (که گاهی بهش ELK Stack هم می‌گن، یعنی مخفف Elasticsearch، Logstash و Kibana) داستانش از سال ۲۰۱۰ شروع می‌شه.

#### 😵‍💫 مشکل Shay 

در سال ۲۰۱۰، Shay Banon در حال ساخت یک اپلیکیشن آشپزی برای همسرش بود که با یک مشکل مشخص روبه‌رو شد:
- **ساختن یک سیستم جستجوی ساده و کارآمد برای حجم زیادی از داده‌ها سخت بود.**
همسر Shay یه مجموعه‌ی بزرگ از دستور پخت‌ها داشت. Shay می‌خواست برای همسرش که در حال تحصیل برای سرآشپز شدن بود، یک ابزار جستجو درست کنه تا بتونه توی مجموعه‌ی بزرگ دستور پخت‌ها (recipes) به راحتی جستجو کنه.
 > مثلاً اگه همسرش می‌خواست دستور پخت‌هایی با "ماهی" پیدا کنه که کمتر از ۴۰۰ کالری داشته باشن، این نرم‌افزار باید سریع جواب می‌داد. 
 > یا مثلاً بگه کدوم دستورها "مرغ" دارن یا کدوم‌ها سریع آماده می‌شن.

در اون زمان، Shay از **Apache Lucene** استفاده می‌کرد، که یه کتابخونه‌ی متن‌باز و قدرتمند برای جستجو بود. 
این نیاز شخصی، جرقه‌ی اولیه‌ی ساخت Elasticsearch رو زد.


⚠️ اما Lucene یه مشکل بزرگ داشت:
-  **سطح پایین (low-level) بود**
-  **استفاده ازش پیچیده و زمان‌بر بود.**

 آقای Shay دنبال سیستمی بود که هم قدرتمند باشه، هم مقیاس‌پذیر، و هم استفاده‌ش برای توسعه‌دهنده‌ها راحت باشه.
 درد اصلیش این بود که نمی‌خواست وقت زیادی صرف مدیریت جزئیات فنی پیچیده کنه. یا به قول معروف نمیخواست خودشو درگیر سطوح پایین پردازشی کند و یک لایه ی سطح بالاتر نیاز داشت.


#### حالا مگه Apache Lucene چه سختی‌ای داشت؟

سرویس Lucene یه کتابخونه‌ی قوی برای جستجو بود، اما چون سطح پایین بود، توسعه‌دهنده رو مجبور می‌کرد خیلی از کارها رو دستی انجام بده.

---
### در اینجا لازمه که ابتدا توضیحاتی در مورد مفاهیم خانواده ایندکس بدهم

#### 📔 ایندکس (Index) 
ایندکس یه جور فهرست یا ساختار منظمه که کمک می‌کنه توی داده‌ها سریع‌تر چیزی که می‌خوایم رو پیدا کنیم. مثل فهرست آخر یه کتاب که بهمون می‌گه یه موضوع خاص توی کدوم صفحه‌هاست.

**مثال ملموس:**  
فرض کنید یه کتاب آشپزی دارید با ۲۰۰ صفحه. می‌خواید دستور پخت "کیک شکلاتی" رو پیدا کنید.
بدون فهرست، باید کل کتاب رو صفحه به صفحه بخونید تا پیداش کنید.
اما اگه یه فهرست (ایندکس) باشه که بگه "کیک شکلاتی: صفحه ۴۵ و ۱۲۰"، مستقیم می‌رید سراغ اون صفحه‌ها.
توی دنیای داده‌ها هم ایندکس همین کار رو می‌کنه: جستجو رو سریع‌تر می‌کنه.

**تعریف علمی‌تر:**  
توی دیتابیس‌ها یا موتورهای جستجو، ایندکس یه ساختار داده‌ست (مثل جدول یا لیست) که به سیستم می‌گه اطلاعات خاص کجا ذخیره شدن، بدون اینکه نیاز باشه کل داده‌ها رو اسکن کنه.

---

#### 📒 ایندکسینگ (Indexing)
ایندکسینگ یعنی فرآیند ساختن اون فهرست یا ایندکس. وقتی داده‌ها رو ایندکس می‌کنیم، داریم اونا رو مرتب و سازمان‌دهی می‌کنیم که بعداً بتونیم سریع‌تر پیداشون کنیم.

**مثال ملموس:**  
فرض کنید یه دفترچه تلفن دارید با اسامی: علی، زهرا، بهرام، سارا. اگه بخواید "زهرا" رو پیدا کنید و اسما مرتب نباشن، باید تک‌تک نگاه کنید.
حالا اگه این اسما رو به ترتیب حروف الفبا مرتب کنید (علی، بهرام، زهرا، سارا)، این کار می‌شه یه نوع ساده از ایندکسینگ.
بعدش پیدا کردن "زهرا" خیلی سریع‌تره چون می‌دونید توی بخش "ز" باید دنبالش بگردید.

**تعریف علمی‌تر:**  
توی سیستم‌های کامپیوتری، ایندکسینگ یعنی اسکن کردن داده‌ها، پیدا کردن الگوها یا کلیدها (مثل کلمات یا مقادیر خاص)، و ذخیره کردن این اطلاعات توی یه ساختار منظم که بعداً بشه ازش برای جستجو استفاده کرد.

---


#### 📓 اینورتد ایندکس (Inverted Index) 
اینورتد ایندکس یه نوع خاص از ایندکسه که به جای اینکه بگه "هر سند چه چیزایی داره(کل : جز ها)"، می‌گه "هر چیز توی چه سندهایی هست(جز:کدام کل ها)".
مثل اینه که فهرست کتاب رو برعکس کنید: به جای "صفحه ۱: سیب و پرتقال"، می‌گه "سیب: صفحه ۱ و ۳".

**مثال ملموس:**  
فرض کنید سه تا یادداشت دارید:  
- یادداشت ۱: "من سیب دوست دارم"  
- یادداشت ۲: "سیب قرمز خوشمزه‌ست"  
- یادداشت ۳: "پرتقال ترش و خوبه"  

یه ایندکس معمولی می‌گه:  
- یادداشت ۱: من، سیب، دوست، دارم  
- یادداشت ۲: سیب، قرمز، خوشمزه‌ست  
- یادداشت ۳: پرتقال، ترش، خوبه  

اما اینورتد ایندکس می‌گه:  
- **سیب**: یادداشت ۱، یادداشت ۲  
- **قرمز**: یادداشت ۲  
- **پرتقال**: یادداشت ۳  
- **دوست**: یادداشت ۱  

حالا اگه بخواید یادداشت‌هایی که "سیب" دارن رو پیدا کنید، مستقیم می‌رید سراغ فهرست "سیب" و می‌بینید توی یادداشت ۱ و ۲ هست. این کار خیلی سریع‌تر از خوندن تک‌تک یادداشت‌هاست.

**تعریف علمی‌تر:**  
اینورتد ایندکس یه ساختار داده‌ست که توی اون، هر کلمه یا کلید (term) به لیستی از شناسه‌های سندهایی که اون کلمه توشون هست، مپ می‌شه. این روش برای جستجوی متنی (مثل سرچ توی گوگل) خیلی بهینه‌ست.

---

#### اینورتد ایندکس کجاها کاربرد داره؟

اینورتد ایندکس توی هر سیستمی که نیاز به جستجوی سریع توی متن داشته باشه، استفاده می‌شه. چند مثال:  

**موتورهای جستجو (مثل گوگل):**  
   - وقتی توی گوگل سرچ می‌کنید "بهترین رستوران تهران"، اینورتد ایندکس به گوگل می‌گه کدوم صفحه‌ها این کلمات رو دارن و کجا هم‌پوشانی دارن.

**سیستم Elasticsearch و سیستم‌های لاگ:**  
   - فرض کنید یه شرکت لاگ‌های سرورش رو توی Elasticsearch ذخیره کرده.
   - اگه بخواد خطاهایی که کلمه "error" توشون هست رو پیدا کنه، اینورتد ایندکس سریع نشون می‌ده این کلمه توی کدوم لاگ‌ها بوده.

**فروشگاه‌های آنلاین:**  
   - توی دیجی‌کالا سرچ می‌کنید "لپ‌تاپ مشکی"، اینورتد ایندکس توضیحات محصولات رو بررسی می‌کنه و سریع محصولاتی که این کلمات توشون هست رو پیدا می‌کنه.

**کتابخونه‌های دیجیتال:**  
   - توی یه آرشیو مقالات، دنبال مقالاتی می‌گردید که "هوش مصنوعی" توشون باشه. اینورتد ایندکس سریع مقالات مرتبط رو پیدا می‌کنه.
 
#### ➕ مزیت های Inverted Index:

- **سرعت:** جستجو توی حجم عظیم داده‌ها رو خیلی سریع می‌کنه.  
- **انعطاف‌پذیری:** می‌تونه جستجوهای پیچیده (مثل چند کلمه‌ای یا با غلط املایی) رو پشتیبانی کنه.  
- **مقیاس‌پذیری:** توی سیستم‌های بزرگ مثل Elasticsearch، به راحتی با داده‌های زیاد کنار میاد.
   
---


#### 🗒️ خلاصه به زبان خیلی ساده

- **ایندکس:** مثل فهرست کتابه، کمک می‌کنه سریع چیزی که می‌خوای رو پیدا کنی.  
- **ایندکسینگ:** ساختن اون فهرست، یعنی مرتب کردن داده‌ها برای جستجوی سریع.  
- **اینورتد ایندکس:** فهرستی که می‌گه هر کلمه توی چه جاهایی هست، و برای سرچ توی متن (مثل گوگل یا Elasticsearch) عالیه.


  
---
#### برگردیم به بحث سختی‌های سیستم Apache Lucene اینا بودن 😵‍💫

- **مدیریت ایندکسینگ**: باید خودتون داده‌ها رو تبدیل به ایندکس می‌کردید، مثلاً متن رو به فهرست معکوس (inverted index) تبدیل کنید.
- **توزیع‌شدگی**: اگه داده‌ها زیاد باشن و روی یه سرور جا نشن، باید خودتون سیستم رو بین چند سرور پخش کنید.
  > که یعنی کد نویسی شبکه و هماهنگی سرورها.
- **مقیاس‌پذیری و اطمینان**: برای اینکه سیستم با داده‌های بزرگ کار کنه و خراب نشه، باید خودتون replication (کپی داده‌ها) و failover (جابجایی در صورت خرابی) رو پیاده‌سازی کنید.
- **عدم وجود API ساده**: برای جستجو، باید خودتون یه رابط کاربری یا API درست می‌کردید.

#### مثال عملی از سختی Lucene:
فرض کنید یه وب‌سایت خبری با ۵ میلیون مقاله دارید و می‌خواهید کاربران بتونن توی مقالات جستجو کنن.

با Lucene باید مراحل زیر رو طی کنید:

1. باید کدی بنویسید که هر مقاله رو بخونه و ایندکس کنه (مثلاً کلمات کلیدی رو استخراج کنه).
2. اگه داده‌ها روی یه سرور جا نشن، باید خودتون سرورها رو هماهنگ کنید و ایندکس‌ها رو پخش کنید.
3. اگه یه سرور خراب بشه، باید خودتون مطمئن بشید که داده‌ها از دست نمیرن.
4. برای جستجوی کاربرها (مثلاً "اخبار ورزشی")، باید یه API جدا بسازید.

این کارها برای یه پروژه‌ی ساده مثل دستور پخت‌ها هم خیلی زیاد بود و Shay رو کلافه کرده بود.



> <img width="100%" alt="lucene" src="https://github.com/user-attachments/assets/3e1bc54c-dee5-473a-be47-2847fc735970" />

> **موقع ثبت و ایندکسینگ چه میشود؟**
> - همانطور که گفتیم متون خوانده میشوند.
> - کلمه به کلمه بررسی میشود.
> - بعد جدول ساخته میشود.
> - ایندکس معکوس قرار داده میشود.
> - هر کلمه مشخص میشود در کدام داکیومنت و چندمین کلمه آن داکیومنت است.



> <img width="100%" alt="lucene query" src="https://github.com/user-attachments/assets/1615f24e-5d66-4cf9-8307-2792d58a6b61"/>

> **موقع جست و جوی کلمه ی blue sky چه میشود؟**
> - محل های اتفاق blue بررسی میشود (داکیومنت اول کلمه سوم - داکیومنت سوم کلمه ی دوم )
> - محل های اتفاق sky هم بررسی میشود (داکیومنت دوم کلمه هشتم - داکیومنت سوم کلمه ی سوم)
> - اشتراک بگیریم
> - آن اتفاقی از blue  مدنظر است که در داکیومنت سوم و کلمه دوم بود
> - آن اتفاقی از sky مدنظر است که او هم در داکیومنت مشترک دوم و کلمه ی بعد از blue است یعنی سوم.
---

#### 🦉 راهکار Shay چی بود؟

آقای Shay تصمیم گرفت یه لایه‌ی جدید روی Lucene بسازد که این مشکلات رو حل کنه.
> راهکارش **Elasticsearch** بود، یه موتور جستجو و تحلیل توزیع‌شده که استفاده ازش **ساده** باشه و از طرفی هم **قدرت** Lucene رو داشته باشه.

#### از نظر تئوریک:
- **پنهان کردن پیچیدگی‌ها**: Elasticsearch از Lucene به عنوان هسته‌ی جستجوش استفاده کرد، اما پیچیدگی‌های مدیریت ایندکس، توزیع‌شدگی و مقیاس‌پذیری رو خودش بر عهده گرفت.
- **معماری توزیع‌شده**: داده‌ها رو به صورت خودکار توی شارد‌ها (shards) پخش کرد و با replica‌ها (کپی‌ها) از خرابی جلوگیری کرد.
- **رابط کاربری ساده**: یه API RESTful با فرمت JSON اضافه کرد که کار باهاش برای توسعه‌دهنده‌ها راحت باشه.

#### از نظر عملی:
- **ارسال داده‌ها**: شما فقط داده‌ها رو به Elasticsearch می‌فرستید، اون خودش ایندکسینگ و پخش کردن داده‌ها رو مدیریت می‌کنه.
- **جستجوی سریع**: با یه درخواست ساده، می‌تونید توی داده‌ها جستجو کنید.
- **مقیاس‌پذیری خودکار**: اگه داده‌ها زیاد بشن، فقط سرور اضافه می‌کنید و Elasticsearch بقیه کار رو انجام می‌ده.

#### مثال عملی با Elasticsearch:
برگردیم به وب‌سایت خبری با ۵ میلیون مقاله. با Elasticsearch:
1. مقالات رو به صورت JSON می‌فرستید:
```json
{
     "title": "Today's Sport News",
     "content": "Barcelona team did ...",
     "date": "2023-10-01"
}
```

2. اکوسیستم Elasticsearch خودش داده‌ها رو ایندکس می‌کنه و توی شارد‌ها پخش می‌کنه.
3. برای جستجو، یه درخواست ساده می‌فرستید:
   ```
   GET /news/_search?q=sport
   ```
   و فوراً نتایج رو می‌گیرید، بدون اینکه نگران سرورها یا خرابی باشید.


### خلاصه تاریخجه
مشکل Shay این بود که ساختن یه سیستم جستجوی مقیاس‌پذیر با Apache Lucene خیلی پیچیده و سخت بود، چون Lucene یه کتابخونه‌ی سطح پایین بود و مدیریتش دستی بود. این مشکل از پروژه‌ی نرم‌افزار آشپزی برای دستور پخت‌های همسرش شروع شد. راهکارش Elasticsearch بود که از نظر تئوریک، پیچیدگی‌های Lucene رو پنهان کرد و از نظر عملی، یه سیستم ساده، توزیع‌شده و قدرتمند ارائه داد که توسعه‌دهنده‌ها بتونن راحت ازش استفاده کنن.

او نیاز به یک موتور جستجوی قوی داشت اما ابزارهای موجود مثل Solr پیچیده بودند.
آقای Shay این لایه رو اضافه کرد و Elasticsearch متولد شد. بعداً ابزارهای Logstash، Kibana و Beats بهش اضافه شدن تا استک کامل بشه.

- 2010: انتشار اولیه Elasticsearch
- 2013: اضافه شدن Logstash به استک
- 2015: معرفی Kibana و Beats
- امروز: یک پلتفرم کامل برای Observability, Security و Enterprise Search
---

